{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "import  pyspark.sql.functions as fun \n",
        "import numpy as np\n",
        "from pyspark.sql.types import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create an RDD from a list of numbers (1,50) using numpy methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n"
          ]
        }
      ],
      "source": [
        "numbers_rdd = sc.parallelize(np.arange(1,50))\n",
        "print(numbers_rdd.collect())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Find the sum, average, maximum, minimum, and count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1225"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Sum\n",
        "numbers_rdd.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25.0"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#avg\n",
        "numbers_rdd.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Count\n",
        "numbers_rdd.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Min\n",
        "numbers_rdd.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Max\n",
        "numbers_rdd.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Count how many numbers are even vs. odd."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ODD Numbers: 25 EVEN Numbers: 24\n"
          ]
        }
      ],
      "source": [
        "even_count = numbers_rdd.filter(lambda x: x % 2 == 0).count()\n",
        "odd_count = numbers_rdd.filter(lambda x: x % 2 != 0).count()\n",
        "print(f\"ODD Numbers: {odd_count} EVEN Numbers: {even_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You have the following data of people info ('Name', 'Age'), answer the following questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Nada ', 25),\n",
              " ('Mona', 30),\n",
              " ('Ahmed', 35),\n",
              " ('Khaled', 40),\n",
              " ('Ahmed', 35),\n",
              " ('Nada ', 25)]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "people_data = [(\"Nada \", 25), (\"Mona\", 30), (\"Ahmed\", 35), (\"Khaled\", 40),(\"Ahmed\", 35), ('Nada ', 25)]\n",
        "rdd_people = sc.parallelize(people_data)\n",
        "rdd_people.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Find the oldest person"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('Khaled', 40)"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd_people.max(key=lambda x: x[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute the average age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "31.666666666666668"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd_people.map(lambda x: x[1]).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Group all the names by their age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(25, [('Nada ', 25), ('Nada ', 25)]),\n",
              " (40, [('Khaled', 40)]),\n",
              " (30, [('Mona', 30)]),\n",
              " (35, [('Ahmed', 35), ('Ahmed', 35)])]"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd_people.groupBy(lambda x: x[1]).mapValues(list).collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Take the following text and put it in a text file named russia.txt and load it into rdd\n",
        "\n",
        "\"Russia is the largest country in the world by land area\n",
        "Moscow is the capital city of Russia\n",
        "The Russian language is one of the most widely spoken languages in the world\n",
        "Russia is known for its rich history and culture\n",
        "The Trans-Siberian Railway is the longest railway line in the world\n",
        "Russia has a strong tradition in literature, music and ballet\n",
        "The country is famous for its cold winters and vast landscapes\n",
        "Russia is a major player in global energy production\n",
        "\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "russia_text =[\n",
        "\"Russia is the largest country in the world by land area\",\n",
        "\"Moscow is the capital city of Russia\",\n",
        "\"The Russian language is one of the most widely spoken languages in the world\",\n",
        "\"Russia is known for its rich history and culture\",\n",
        "\"The Trans-Siberian Railway is the longest railway line in the world\",\n",
        "\"Russia has a strong tradition in literature, music and ballet\",\n",
        "\"The country is famous for its cold winters and vast landscapes\",\n",
        "\"Russia is a major player in global energy production\",\n",
        "\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Russia is the largest country in the world by land area',\n",
              " 'Moscow is the capital city of Russia',\n",
              " 'The Russian language is one of the most widely spoken languages in the world',\n",
              " 'Russia is known for its rich history and culture',\n",
              " 'The Trans-Siberian Railway is the longest railway line in the world',\n",
              " 'Russia has a strong tradition in literature, music and ballet',\n",
              " 'The country is famous for its cold winters and vast landscapes',\n",
              " 'Russia is a major player in global energy production']"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd_russia = sc.parallelize(russia_text)\n",
        "rdd_russia.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "# rdd_russia = sc.textFile(\"/data/russia.txt\")\n",
        "# rdd_russia.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Count the total number of lines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd_russia.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Count how many lines contain the word \"Russia\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd_russia.filter(lambda line: \"Russia\" in line).count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Find the most 5 frequent word in the file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('the', 10), ('is', 7), ('in', 5), ('russia', 5), ('world', 3)]"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words_rdd = rdd_russia.flatMap(lambda line: line.lower().split())\n",
        "word_counts = words_rdd.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
        "word_counts.takeOrdered(5, key=lambda x: -x[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tokenize words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['russia', 'is', 'the', 'largest', 'country', 'in', 'the', 'world', 'by', 'land', 'area', 'moscow', 'is', 'the', 'capital', 'city', 'of', 'russia', 'the', 'russian', 'language', 'is', 'one', 'of', 'the', 'most', 'widely', 'spoken', 'languages', 'in', 'the', 'world', 'russia', 'is', 'known', 'for', 'its', 'rich', 'history', 'and', 'culture', 'the', 'trans-siberian', 'railway', 'is', 'the', 'longest', 'railway', 'line', 'in', 'the', 'world', 'russia', 'has', 'a', 'strong', 'tradition', 'in', 'literature,', 'music', 'and', 'ballet', 'the', 'country', 'is', 'famous', 'for', 'its', 'cold', 'winters', 'and', 'vast', 'landscapes', 'russia', 'is', 'a', 'major', 'player', 'in', 'global', 'energy', 'production']\n"
          ]
        }
      ],
      "source": [
        "tokenized_words = rdd_russia.flatMap(lambda line: line.lower().split()).collect()\n",
        "print(tokenized_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Remove stopwords (a, the, is, to, in, of). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['russia', 'largest', 'country', 'world', 'by', 'land', 'area', 'moscow', 'capital', 'city', 'russia', 'russian', 'language', 'one', 'most', 'widely', 'spoken', 'languages', 'world', 'russia', 'known', 'for', 'its', 'rich', 'history', 'and', 'culture', 'trans-siberian', 'railway', 'longest', 'railway', 'line', 'world', 'russia', 'has', 'strong', 'tradition', 'literature,', 'music', 'and', 'ballet', 'country', 'famous', 'for', 'its', 'cold', 'winters', 'and', 'vast', 'landscapes', 'russia', 'major', 'player', 'global', 'energy', 'production']\n"
          ]
        }
      ],
      "source": [
        "stopwords = {'a', 'the', 'is', 'to', 'in', 'of'}\n",
        "filtered_words = rdd_russia.flatMap(lambda line: line.lower().split())\\\n",
        "                          .filter(lambda word: word not in stopwords)\\\n",
        "                          .collect()\n",
        "print(filtered_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Count the frequency of each word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('world', 3), ('by', 1), ('land', 1), ('history', 1), ('and', 3), ('winters', 1), ('spoken', 1), ('culture', 1), ('strong', 1), ('largest', 1), ('russian', 1), ('famous', 1), ('cold', 1), ('its', 2), ('ballet', 1), ('capital', 1), ('language', 1), ('most', 1), ('widely', 1), ('known', 1), ('line', 1), ('music', 1), ('energy', 1), ('city', 1), ('languages', 1), ('trans-siberian', 1), ('longest', 1), ('has', 1), ('major', 1), ('country', 2), ('area', 1), ('for', 2), ('player', 1), ('production', 1), ('moscow', 1), ('vast', 1), ('global', 1), ('literature,', 1), ('landscapes', 1), ('one', 1), ('railway', 2), ('tradition', 1), ('russia', 5), ('rich', 1)]\n"
          ]
        }
      ],
      "source": [
        "word_freq = rdd_russia.flatMap(lambda line: line.lower().split())\\\n",
        "                     .filter(lambda word: word not in stopwords)\\\n",
        "                     .map(lambda word: (word, 1))\\\n",
        "                     .reduceByKey(lambda a, b: a + b)\\\n",
        "                     .collect()\n",
        "print(word_freq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "schema = 'id integer, name string, age integer, salary integer' \n",
        "data = [\n",
        "    (1, \"Ali\", 25, 4000),\n",
        "    (2, \"Mariam\", 30, 6000),\n",
        "    (3, \"Omar\", 35, 7000),\n",
        "    (4, \"Sara\", 28, 5000),\n",
        "    (5, \"Omar\", 25, 6500),\n",
        "    (6, \"Mariam\", 26, 7500)\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(data,schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show schema and first 2 rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- salary: integer (nullable = true)\n",
            "\n",
            "+---+------+---+------+\n",
            "| id|  name|age|salary|\n",
            "+---+------+---+------+\n",
            "|  1|   Ali| 25|  4000|\n",
            "|  2|Mariam| 30|  6000|\n",
            "+---+------+---+------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()\n",
        "df.show(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Select only name and salary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------+\n",
            "|  name|salary|\n",
            "+------+------+\n",
            "|   Ali|  4000|\n",
            "|Mariam|  6000|\n",
            "|  Omar|  7000|\n",
            "|  Sara|  5000|\n",
            "|  Omar|  6500|\n",
            "|Mariam|  7500|\n",
            "+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select(\"name\", \"salary\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Find the average salary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+\n",
            "|avg(salary)|\n",
            "+-----------+\n",
            "|     6000.0|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import avg\n",
        "df.select(avg(\"salary\")).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filter employees older than 28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+------+---+------+\n",
            "| id|  name|age|salary|\n",
            "+---+------+---+------+\n",
            "|  2|Mariam| 30|  6000|\n",
            "|  3|  Omar| 35|  7000|\n",
            "+---+------+---+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.filter(df.age > 28).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Count distinct values in the name column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.select(\"name\").distinct().count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Group by a the name column and find average salary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-------+\n",
            "|  name|Average|\n",
            "+------+-------+\n",
            "|   Ali| 4000.0|\n",
            "|Mariam| 6750.0|\n",
            "|  Omar| 6750.0|\n",
            "|  Sara| 5000.0|\n",
            "+------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import avg\n",
        "df.groupBy(\"name\").agg(avg(\"salary\").alias(\"Average\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from pyspark.sql import Row\n",
        "\n",
        "data = [\n",
        "    Row(Id=\"emp1\", Name=\"John\", Sales=None),\n",
        "    Row(Id=\"emp2\", Name=None, Sales=None),\n",
        "    Row(Id=\"emp3\", Name=None, Sales=345.0),\n",
        "    Row(Id=\"emp4\", Name=\"Cindy\", Sales=456.0)\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+-----+-----+\n",
            "|  Id| Name|Sales|\n",
            "+----+-----+-----+\n",
            "|emp1| John| NULL|\n",
            "|emp2| NULL| NULL|\n",
            "|emp3| NULL|345.0|\n",
            "|emp4|Cindy|456.0|\n",
            "+----+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df1 = spark.createDataFrame(data)\n",
        "df1.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df1 = spark.read.csv(\"/data/NullData.csv\", header=True, inferSchema=True) #this file in shared folder\n",
        "# df1.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Find the avg sales "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "400.5\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import avg\n",
        "avg_sales = df1.select(avg(\"Sales\")).collect()[0][0]\n",
        "print(avg_sales)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Replace null name with 'Unknown' and sales with the avg sales of the column "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+-------+-----+\n",
            "|  Id|   Name|Sales|\n",
            "+----+-------+-----+\n",
            "|emp1|   John|400.5|\n",
            "|emp2|Unknown|400.5|\n",
            "|emp3|Unknown|345.0|\n",
            "|emp4|  Cindy|456.0|\n",
            "+----+-------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import when, col, lit\n",
        "\n",
        "df_cleaned = df1.withColumn(\"Name\", when(col(\"Name\").isNull(), \"Unknown\").otherwise(col(\"Name\")))\\\n",
        "                .withColumn(\"Sales\", when(col(\"Sales\").isNull(), avg_sales).otherwise(col(\"Sales\")))\n",
        "df_cleaned.show()"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
